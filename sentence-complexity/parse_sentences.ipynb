{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "#from nltk.parse import stanford\n",
    "\n",
    "os.environ['STANFORD_PARSER'] = '~/Downloads/stanford-parser-full-2018-10-17'\n",
    "os.environ['STANFORD_MODELS'] = '~/Downloads/stanford-parser-full-2018-10-17'\n",
    "os.environ['CLASSPATH'] = '~/Downloads/stanford-parser-full-2018-10-17/*'\n",
    "\n",
    "parser = nltk.parse.corenlp.CoreNLPParser(url='http://localhost:9000')\n",
    "#parser = stanford.StanfordParser(model_path=\"~/Downloads/stanford-parser-full-2018-10-17/edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = defaultdict(lambda: [0,0]) # keep a tuple: total, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = glob.glob('*_sentences.txt')\n",
    "# order of paths is deterministic\n",
    "#last_index = data_path.index(\"29775466_sentences.txt\")\n",
    "#print(last_index)\n",
    "#data_path = data_path[last_index+1:]\n",
    "data_path = data_path[:9]\n",
    "#print(data_path)\n",
    "#print(data_path[0])\n",
    "\n",
    "data_path = []\n",
    "ids_left = ['18559389', '270280', '29747722', '45033570']\n",
    "for idnum in ids_left:\n",
    "    data_path.append(idnum + \"_sentences.txt\")\n",
    "\n",
    "# clear out if anything was already counted for the next user\n",
    "counts[data_path[0].split(\"_\")[0]] = [0,0]\n",
    "\n",
    "#counts['21235741'] = [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18559389\n",
      "270280\n",
      "29747722\n",
      "45033570\n"
     ]
    }
   ],
   "source": [
    "#sentences = [\"Hello, My name is Melroy.\", \"What is your name?\", \"This sentence, with its many, even more than two, nested clauses (such as this one), is complicated.\"]\n",
    "\n",
    "for filename in data_path:\n",
    "    curr_file = open(filename, \"r\")\n",
    "    user = filename.split(\"_\")[0]\n",
    "    print(user)\n",
    "    for line in curr_file:\n",
    "        \n",
    "        # skip lines with any unicode\n",
    "        if not all(ord(c) < 128 for c in line):\n",
    "            continue\n",
    "        \n",
    "        #print(line)\n",
    "        \n",
    "        #try\n",
    "        parsed = parser.parse(line.split())\n",
    "        # answer by alvas on https://stackoverflow.com/questions/13883277/stanford-parser-and-nltk\n",
    "        # also here: https://github.com/nltk/nltk/wiki/Stanford-CoreNLP-API-in-NLTK\n",
    "        \n",
    "        #catch error\n",
    "        # skip this line\n",
    "\n",
    "        tree = next(parsed)\n",
    "        #print(tree)\n",
    "        height = tree.height()\n",
    "        \n",
    "        # update height total\n",
    "        counts[user][0] += height\n",
    "        # update count\n",
    "        counts[user][1] += 1\n",
    "        \n",
    "        #print(average_depth[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10820250': 7.870967741935484,\n",
      " '13207027': 8.504955947136564,\n",
      " '14137183': 7.686684715727295,\n",
      " '18559389': 6.761904761904762,\n",
      " '18559680': 7.81063321385902,\n",
      " '19458971': 8.269116775340843,\n",
      " '20963086': 8.142857142857142,\n",
      " '21235741': 8.074409127954361,\n",
      " '21235813': 8.758374011109241,\n",
      " '21241679': 9.496,\n",
      " '21349729': 8.078125,\n",
      " '21755924': 7.85,\n",
      " '22207515': 9.736842105263158,\n",
      " '22276941': 8.40952380952381,\n",
      " '23354087': 9.5,\n",
      " '24927292': 9.28,\n",
      " '26498711': 8.027397260273972,\n",
      " '26508082': 8.060880195599022,\n",
      " '26514517': 8.234943324077024,\n",
      " '26601370': 8.8,\n",
      " '270093': 6.833333333333333,\n",
      " '270280': 4.9411764705882355,\n",
      " '27380802': 9.045096056622851,\n",
      " '27546073': 8.532754880694144,\n",
      " '28068527': 7.435726210350584,\n",
      " '28222063': 8.057856465380967,\n",
      " '28880161': 7.84,\n",
      " '29652195': 8.20948960713897,\n",
      " '29666163': 8.900278551532033,\n",
      " '29747722': 7.785714285714286,\n",
      " '29750591': 7.522760646108663,\n",
      " '29775461': 8.742245522062035,\n",
      " '29775466': 8.578125,\n",
      " '29818898': 9.176191886289606,\n",
      " '29846726': 7.620658949243099,\n",
      " '45033570': 7.75,\n",
      " '46185459': 7.3,\n",
      " '51427894': 9.2}\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "average_depth = defaultdict(float)\n",
    "for user in counts:\n",
    "    average_depth[user] = counts[user][0]/counts[user][1]\n",
    "pprint(dict(average_depth))\n",
    "print(len(average_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12270\n"
     ]
    }
   ],
   "source": [
    "print(counts['21235741'][1]) # Jim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_name = {'10820250': 'Jack',\n",
    "             '13207027': 'John',\n",
    "             '14137183': 'Peter',\n",
    "             '18559389': 'Anna',\n",
    "             '18559680': 'Ethan',\n",
    "             '19458971': 'Alex',\n",
    "             '20963086': 'Kylie',\n",
    "             '21235741': 'Jim',\n",
    "             '21235813': 'Nathan',\n",
    "             '21241679': 'Aaron',\n",
    "             '21349729': 'Sarah',\n",
    "             '21755924': 'Bob',\n",
    "             '22207515': 'Claire',\n",
    "             '22276941': 'Sally',\n",
    "             '23354087': 'Mike',\n",
    "             '24927292': 'Tim',\n",
    "             '26498711': 'Nina',\n",
    "             '26508082': 'Jacob',\n",
    "             '26514517': 'Lisa',\n",
    "             '26601370': 'Mitch',\n",
    "             '270093': 'Alan',\n",
    "             '270280': 'Tom',\n",
    "             '27380802': 'Jill',\n",
    "             '27546073': 'Walter',\n",
    "             '28068527': 'Simon',\n",
    "             '28222063': 'Annie',\n",
    "             '28880161': 'Chris',\n",
    "             '29652195': 'Nancy',\n",
    "             '29666163': 'Michael',\n",
    "             '29747722': 'Jason',\n",
    "             '29750591': 'Trey',\n",
    "             '29775461': 'Nicole',\n",
    "             '29775466': 'Liza',\n",
    "             '29818898': 'Thomas',\n",
    "             '29846726': 'Isaac',\n",
    "             '45033570': 'Patrick',\n",
    "             '46185459': 'Zo',\n",
    "             '51427894': 'Natalie'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claire & 9.737 \\\\\n",
      "Mike & 9.500 \\\\\n",
      "Aaron & 9.496 \\\\\n",
      "Tim & 9.280 \\\\\n",
      "Natalie & 9.200 \\\\\n",
      "Thomas & 9.176 \\\\\n",
      "Jill & 9.045 \\\\\n",
      "Michael & 8.900 \\\\\n",
      "Mitch & 8.800 \\\\\n",
      "Nathan & 8.758 \\\\\n",
      "Nicole & 8.742 \\\\\n",
      "Liza & 8.578 \\\\\n",
      "Walter & 8.533 \\\\\n",
      "John & 8.505 \\\\\n",
      "Sally & 8.410 \\\\\n",
      "Alex & 8.269 \\\\\n",
      "Lisa & 8.235 \\\\\n",
      "Nancy & 8.209 \\\\\n",
      "Kylie & 8.143 \\\\\n",
      "Sarah & 8.078 \\\\\n",
      "Jim & 8.074 \\\\\n",
      "Jacob & 8.061 \\\\\n",
      "Annie & 8.058 \\\\\n",
      "Nina & 8.027 \\\\\n",
      "Jack & 7.871 \\\\\n",
      "Bob & 7.850 \\\\\n",
      "Chris & 7.840 \\\\\n",
      "Ethan & 7.811 \\\\\n",
      "Jason & 7.786 \\\\\n",
      "Patrick & 7.750 \\\\\n",
      "Peter & 7.687 \\\\\n",
      "Isaac & 7.621 \\\\\n",
      "Trey & 7.523 \\\\\n",
      "Simon & 7.436 \\\\\n",
      "Zo & 7.300 \\\\\n",
      "Alan & 6.833 \\\\\n",
      "Anna & 6.762 \\\\\n",
      "Tom & 4.941 \\\\\n",
      "\n",
      "length: 38\n"
     ]
    }
   ],
   "source": [
    "#save_results = open(\"save_results.txt\", \"a\")\n",
    "for key_value_pair in sorted(average_depth.items(),\n",
    "           key=lambda k_v: k_v[1],\n",
    "           reverse=True):\n",
    "        \n",
    "        user = key_value_pair[0]\n",
    "        average = key_value_pair[1]\n",
    "        \n",
    "        #print(fake_name[user] + \"\\t\" + str(average))\n",
    "        print(\"{} & {:.3f} \\\\\\\\\".format(fake_name[user], average)) # latex table format\n",
    "        #save_results.write(fake_name[user] + \"\\t\" + str(average) + \"\\n\")\n",
    "\n",
    "print(\"\\nlength: \" + str(len(average_depth)))\n",
    "#save_results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line in sentences:\n",
    "#     #print line\n",
    "#     for sentence in line:\n",
    "#         xml = \"\"\n",
    "#         print sentence\n",
    "#         sentence.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: convert into element tree\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
